{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _Marco Tulio Masselli Rainho Teixeira_\n",
    "\n",
    "Nome: _Talissa Gonçalves Albertini_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador automático de qualidade de investimentos em ações\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição da Base de Dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados ultilizada neste projeto é composta por indicadores financeiros coletados ao longo de vários anos (1986-2020) da empresa Microsoft\n",
    "\n",
    "Indicadores do DataSet Trimestral\n",
    "* DATE: Dada de coleta das informações\n",
    "* NET_INCOME: A diferença entre o lucro bruto e as despesas (em $10^6$ dólares)\n",
    "* CF_FREE_CASH_FLOW: \n",
    "* CF_CASH_FROM_OPER:\n",
    "* CF_CASH_FROM_INV_ACT:\n",
    "* CF_CASH_FROM_FNC_ACT:\n",
    "* CUR_RATIO:\n",
    "* TOT_DEBT_TO_COM_EQY:\n",
    "* RETURN_COM_EQY:\n",
    "\n",
    "Indicadores do DataSet Diário\n",
    "* DATE: Dada de coleta das informações\n",
    "* CUR_MKT_CAP : Valor de mercado, valor de uma ação vezes o número total ed ações\n",
    "* TURNOVER : Indica o quão rápido a empresa consegue arrecadar dinheito com o seu inventário\n",
    "* PX LAST : Preço da ação \n",
    "* EQY_SH_OUT :\n",
    "* PE RATIO :\n",
    "* PX_TO_BOOK_RATIO :\n",
    "* EQY_DPS :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnica utilizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão logística multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo do Projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto tem o objetivo realizar a análise de indicadores financeiros de uma determinada ação do portfólio e responder a seguinte questão: Esta ação deve ser matida no portfólio ou não ? O critério relevante para responder essa questão é basicamente a probabilidade dessa ação valorizar durante o próximo trimestre, dado que parte significante dos indicadores são trimestrais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao para formatacao das ceulas\n",
    "\n",
    "def disposicao_lateral(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparação do ambiente do Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display_html\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "# obs: descobrir por que as bibliotecas nao estao funcionando\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.plotly as py\n",
    "#from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregando a base de dados com os indicadores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('Dados_BBG.xlsx')\n",
    "dft1 = pd.read_excel(xls, 'MSFT-Quarterly')\n",
    "dft2 = pd.read_excel(xls, 'MSFT-Daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dft1.iloc[6:133, 1:] # dft trimestral\n",
    "\n",
    "dfd = dft2.iloc[6:, 1:] # dft diário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tratamento do banco de dados de treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rectify the date columns\n",
    "dft.iloc[:, 0] = dft.iloc[:, 0].dt.date \n",
    "\n",
    "dfd.iloc[:, 0] = dfd.iloc[:, 0].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c08080264244>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set the column's names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcolumns_dft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Unnamed: 1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcolumns_dft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Unnamed: 3'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcolumns_dft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the column's names \n",
    "\n",
    "columns_dft = dft1.iloc[4,[1,3,5,7,9,11,13,15,17,19]].array  \n",
    "dft.rename( columns={'Unnamed: 1':columns_dft[0]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 3':columns_dft[1]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 5':columns_dft[2]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 7':columns_dft[3]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 9':columns_dft[4]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 11':columns_dft[5]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 13':columns_dft[6]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 15':columns_dft[7]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 17':columns_dft[8]}, inplace=True )\n",
    "dft.rename( columns={'Unnamed: 19':columns_dft[9]}, inplace=True )\n",
    "\n",
    "columns_dfd = dft2.iloc[4,[1,3,5,7,9,11,13]].array  \n",
    "dfd.rename( columns={'Unnamed: 1':columns_dfd[0]}, inplace=True )\n",
    "dfd.rename( columns={'Unnamed: 3':columns_dfd[1]}, inplace=True )\n",
    "dfd.rename( columns={'Unnamed: 5':columns_dfd[2]}, inplace=True )\n",
    "dfd.rename( columns={'Unnamed: 7':columns_dfd[3]}, inplace=True )\n",
    "dfd.rename( columns={'Unnamed: 9':columns_dfd[4]}, inplace=True )\n",
    "dfd.rename( columns={'Unnamed: 11':columns_dfd[5]}, inplace=True )\n",
    "dfd.rename( columns={'Unnamed: 13':columns_dfd[6]}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicadores financeiros que serao analisados\n",
    "print(columns_dft)\n",
    "print(columns_dfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of unnamed columns thar remained\n",
    "dft = dft.loc[:, ~dft.columns.str.contains('^Unnamed')]\n",
    "\n",
    "dfd = dfd.loc[:, ~dfd.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectify the data type\n",
    "indicators_dft = ['NET_INCOME', 'CF_FREE_CASH_FLOW', 'CF_CASH_FROM_OPER', 'CF_CASH_FROM_INV_ACT', 'CF_CASH_FROM_FNC_ACT', 'CUR_RATIO',  'TOT_DEBT_TO_COM_EQY', 'RETURN_COM_EQY', 'EQY_DPS']\n",
    "for indicator in indicators_dft:\n",
    "    dft[indicator] = dft[indicator].astype(float)\n",
    "    \n",
    "dft['DATE'] = pd.to_datetime(dft['DATE'])\n",
    "\n",
    "\n",
    "\n",
    "indicators_dfd = ['CUR_MKT_CAP', 'TURNOVER', 'PX_LAST', 'EQY_SH_OUT', 'PE_RATIO', 'PX_TO_BOOK_RATIO']\n",
    "for indicator in indicators_dfd:\n",
    "    dfd[indicator] = dfd[indicator].astype(float)\n",
    "    \n",
    "dfd['DATE'] = pd.to_datetime(dfd['DATE'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipos de variavel\n",
    "disposicao_lateral(dft.dtypes.to_frame(),dfd.dtypes.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date as index\n",
    "dft = dft.set_index('DATE')\n",
    "dfd = dfd.set_index('DATE')\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converção de tabela diaria em trimestral e uniormizacao dos nomes dos df\n",
    "dft1 = dft\n",
    "dft2 = dfd.resample('Q').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria a coluna da variavel target , para ser usada na regressao logistica \n",
    "dft2['return'] = (dft2['PX_LAST'].diff()>0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# junta os data frames \n",
    "dftmerged = pd.DataFrame()\n",
    "dftmerged = dft1.merge(dft2, left_on='DATE', right_on='DATE')\n",
    "dftmerged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dft.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descricao dos df\n",
    "# disposicao_lateral(dft1.describe().T, dft2.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness of the indicators\n",
    "#dft1.skew()\n",
    "#dft2.skew()\n",
    "# disposicao_lateral(dft1.skew().to_frame(), dft2.skew().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values\n",
    "#dft1.isna().sum()\n",
    "#dft2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation table dft1\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "sb.heatmap(dft1.corr(),annot=True,linewidths=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation table dft2\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "sb.heatmap(dft2.corr(),annot=True,linewidths=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# litsas de correlacao entre a variavel targef e as variaveis features\n",
    "\n",
    "price_corr =  dftmerged.corr()['PX_LAST'].sort_values(ascending=False).to_frame()\n",
    "price_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizaca dos indicadores no tempo\n",
    "fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(12,20))\n",
    "dftmerged.plot(ax = axes[0],subplots=True);\n",
    "# plot second pandas frame in subplot style\n",
    "#dft2.plot(ax = axes[1],subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adiciona a coluna return no dfd somente para alguma possivel comparacao com uma variavel nos graficos abaixo\n",
    "dfd['return'] = (dfd['PX_LAST'].diff()>0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 scatter sobrepostos de dois indicadores, um scatter para os dias em que a acao valorizou, e outro para os quais ela desvalorizou\n",
    "profit = dfd.loc[dfd['return'] == 1, :] \n",
    "loss = dfd.loc[dfd['return'] == 0, :]\n",
    "\n",
    "plt.scatter(profit.loc[: , 'PE_RATIO'], profit.loc[: , 'CUR_MKT_CAP'], s=10, label='Profitble')\n",
    "plt.scatter(loss.loc[:, 'PE_RATIO'], loss.loc[:, 'CUR_MKT_CAP'], s=10, label='Not profitable')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop para plotar o mesmo tipo de grafico da celula anterior, mas com um grafico para cada indicador\n",
    "\n",
    "#for indicator in indicators_dfd: \n",
    "#    plt.scatter(profit.loc[: , indicator], profit.loc[: , 'PX_TO_BOOK_RATIO'], s=10, label='profitble')\n",
    "#    plt.scatter(loss.loc[:, indicator], loss.loc[:, 'PX_TO_BOOK_RATIO'], s=10, label='Not profitable')\n",
    "#    plt.legend()\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "dfd['PX_LAST'].rolling(window=30).mean().plot(label='30 Day Avg')\n",
    "dfd['PX_LAST'].plot(label='PX_LAST')\n",
    "plt.legend()\n",
    "# usar loc['2008-01-01':'2009-01-01'] qunado as colunas ja tiverem nomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao da regressao logistica multipla\n",
    "def Classifier(df):\n",
    "    target = df.loc[:,'return'].head()\n",
    "    indicators = df.iloc[:,:-1].head()\n",
    "    train_indicators, test_indicators, train_target, test_target = train_test_split(indicators, target, train_size=0.7)\n",
    "    linear_model.LogisticRegression().fit(train_indicators, train_target)\n",
    "    # retorna valores de test_target, baseado nos valores de test_indicators\n",
    "    return LogisticRegression().predict(test_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs: a funcao nao esta funcionando pq falta arrumar os NaN no dfmerged\n",
    "# possibilidades: atribuir valores de medias ?, regressao linear ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste de acuracia do classificador\n",
    "\n",
    "LogisticRegression().score(test_indicators, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bobliografia \n",
    "\n",
    "# regressao logistica: https://dataaspirant.com/2017/05/15/implement-multinomial-logistic-regression-python/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
